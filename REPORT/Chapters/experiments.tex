In this chapter, we present experimental results of the LPNN approach. The evaluation is qualitative, since the nature of light probes and their optimal placement is subjective to the user and the needs of the application. We focus mainly on speed in relation to light probe layout given by the tool. We compare performance results to LumiProbes \parencite{Vardis2021}. All experiments were conducted in Unity on a system comprising of an NVIDIA RTX2060M GPU, 16GB DDR4 RAM and an Intel i7-9750H CPU, on a Windows 10 Operating System.

\section{Performance}
\label{sec:4_performance}
The LPNN approach speeds up light probe placement by orders of magnitude faster than other approaches, but it may suffer from occasional misplacement; probes that were placed in positions that are not vital, leading to oversampling. In experiments where LumiProbes and LPNN were requested to place close to the same amount of light probes in the same scene, LPNN time stayed close to constant, typically up to a few seconds, regardless of the scenario or the amount requested. Results for various amounts of light probes and scenes are presented in table \ref{table:times}. Times are averaged over multiple runs. Units are represented in minutes (m), seconds (s), or milliseconds (ms). Where applicable, we also append the settings used for each tool. For LumiProbes, settings include the grid parameters and the evaluation-point count. All other settings are as follows: Evaluation point placement type is set to Poisson, Decimation type is set to Medium, Decimation directions are averaged, Decimation metric is set to  Chrominance, Minimum LP set is disabled, and Maximum Error is set to 3. For LPNN, settings include the threshold value used for the specific result and the cell size of the 3D grid, in order. Figures for the results are shown in section \ref{sec:4_quality}.

\begin{table}
	\centering
\begin{tabular}{ |c||c|c|c|c|c|  }
	\hline
	\multicolumn{6}{|c|}{Execution time} \\
	\hline
	Method & Scene & Time & P. Count & P. Present (\& Removed) & Settings\\
	\hline
	LumiProbes & Sponza   &          &     &      &      \\
	\cline{2-6}
	           & Office   & 51.059s  & 144 & 84 (60)  & (12,3,4), 128\\
	           &          & 919.134s  & 288 & 182 (106)  & (12,3,8), 256\\
	\cline{2-6}
	           & Corridor & 161.151s & 180 & 120 (60) & (20,3,3), 256\\
	           &          & 477.648s & 243 & 147 (96) & (27,3,3), 256\\
	\hline
	\hline
	Ours       & Sponza    &       &     &           &             \\
	\cline{2-6}
			   & Office   & \textbf{7.8ms}  & 140 & 34 (106)  &  0.758, 1.87 \\
               &          & \textbf{25.2ms} & 832 & 117 (715) &  0.859, 1.10 \\
    \cline{2-6}
    		   & Corridor & \textbf{10.9ms} & 186 & 84 (102)  & 0.549, 1.94 \\
               &          & \textbf{15.7ms} & 246 & 95 (151)  & 0.615, 1.50 \\
               
	\hline
\end{tabular}
\caption{Execution time for LPNN and LumiProbes on a select number of scenes and probe counts. \textit{P. count} represents the total amount of probes in the scene, before simplification. \textit{P. Present} depict the final amount of probes after running the tools. The number in parenthesis is the amount of probes removed by the tool, in respect to the settings. Fastest times are shown in \textbf{bold}.}
\label{table:times}
\end{table}

\section{Quality}
\label{sec:4_quality}
The tools were tested on the aforementioned edited Sponza scene \parencite{Sponza2017}, Corridor scene \parencite{Corridor2021} and Office scene \parencite{Office2021}. We will present the qualitative results. As seen in figure \ref{}, LPNN correctly places light probes in areas of high variance.

